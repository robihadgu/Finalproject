<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>Deepfake Technology – Visual Overview & Ethical Impact</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta
        name="description"
        content="A visual, easy-to-understand explanation of deepfake technology, how it works, real examples, and ethical issues."
    />
    <style>
        :root {
            --bg: #020617;
            --bg-alt: #0b1120;
            --card: #0f172a;
            --accent: #4f46e5;
            --accent-soft: rgba(79, 70, 229, 0.18);
            --text: #f9fafb;
            --muted: #9ca3af;
            --border: #1f2937;
            --max-width: 1080px;
        }

        * {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
                sans-serif;
            background: radial-gradient(circle at top, #111827 0, #020617 55%);
            color: var(--text);
            line-height: 1.6;
        }

        a {
            color: var(--accent);
            text-decoration: none;
        }

        a:hover {
            text-decoration: underline;
        }

        /* NAV */
        header {
            position: sticky;
            top: 0;
            z-index: 20;
            backdrop-filter: blur(16px);
            background: linear-gradient(
                to bottom,
                rgba(2, 6, 23, 0.96),
                rgba(2, 6, 23, 0.85)
            );
            border-bottom: 1px solid var(--border);
        }

        .nav {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 0.7rem 1.4rem;
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 1rem;
        }

        .nav-title {
            font-weight: 600;
            letter-spacing: 0.06em;
            font-size: 0.9rem;
            text-transform: uppercase;
            color: var(--muted);
        }

        .nav-links {
            display: flex;
            flex-wrap: wrap;
            gap: 0.6rem;
            font-size: 0.85rem;
        }

        .nav-links a {
            padding: 0.25rem 0.7rem;
            border-radius: 999px;
            border: 1px solid transparent;
            color: var(--muted);
        }

        .nav-links a:hover {
            border-color: var(--accent-soft);
            background: rgba(15, 23, 42, 0.95);
            color: var(--text);
            text-decoration: none;
        }

        /* LAYOUT */
        main {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 2.4rem 1.4rem 3.2rem;
        }

        section {
            margin-bottom: 3rem;
        }

        h1,
        h2,
        h3 {
            font-weight: 700;
            line-height: 1.25;
        }

        h1 {
            font-size: clamp(2.4rem, 3vw + 1.8rem, 3.3rem);
            margin: 0 0 0.6rem;
        }

        h2 {
            font-size: 1.8rem;
            margin-bottom: 0.9rem;
        }

        h3 {
            font-size: 1.1rem;
            margin-bottom: 0.35rem;
        }

        p {
            margin: 0.35rem 0 0.55rem;
            color: var(--muted);
        }

        .hero {
            display: grid;
            grid-template-columns: minmax(0, 3fr) minmax(0, 2.4fr);
            gap: 2rem;
            align-items: center;
            margin-bottom: 2.7rem;
        }

        .hero-tag {
            display: inline-flex;
            align-items: center;
            gap: 0.4rem;
            padding: 0.25rem 0.6rem;
            border-radius: 999px;
            background: rgba(15, 23, 42, 0.9);
            border: 1px solid var(--border);
            font-size: 0.8rem;
            color: var(--muted);
            margin-bottom: 0.8rem;
        }

        .hero-tag span.dot {
            width: 7px;
            height: 7px;
            border-radius: 999px;
            background: radial-gradient(circle, #22c55e, #15803d);
        }

        .hero-subtitle {
            font-size: 1.02rem;
            max-width: 34rem;
        }

        .meta {
            margin-top: 0.7rem;
            font-size: 0.85rem;
            color: var(--muted);
        }

        .meta strong {
            color: var(--text);
        }

        .hero-figure {
            border-radius: 1.4rem;
            background: radial-gradient(circle at top left, #1e293b 0, #020617 55%);
            border: 1px solid var(--border);
            padding: 1.1rem 1.2rem 1.25rem;
        }

        .hero-img-grid {
            display: grid;
            grid-template-columns: repeat(2, minmax(0, 1fr));
            gap: 0.4rem;
            margin-bottom: 0.6rem;
        }

        figure {
            margin: 0;
        }

        img {
            max-width: 100%;
            border-radius: 0.85rem;
            display: block;
        }

        figcaption {
            margin-top: 0.3rem;
            font-size: 0.78rem;
            color: var(--muted);
        }

        .pill {
            display: inline-flex;
            align-items: center;
            gap: 0.35rem;
            padding: 0.3rem 0.65rem;
            border-radius: 999px;
            border: 1px solid rgba(148, 163, 184, 0.4);
            font-size: 0.75rem;
            background: rgba(15, 23, 42, 0.85);
        }

        .pill-icon {
            width: 13px;
            height: 13px;
            border-radius: 999px;
            border: 1px solid rgba(148, 163, 184, 0.7);
            display: inline-flex;
            align-items: center;
            justify-content: center;
            font-size: 0.62rem;
        }

        .card {
            border-radius: 1.15rem;
            background: rgba(15, 23, 42, 0.95);
            border: 1px solid var(--border);
            padding: 1.15rem 1.25rem;
            margin-top: 0.7rem;
        }

        .card-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(230px, 1fr));
            gap: 1.1rem;
        }

        .step-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(230px, 1fr));
            gap: 1rem;
            margin-top: 0.6rem;
        }

        .step {
            border-radius: 1rem;
            border: 1px dashed var(--border);
            padding: 0.9rem;
            background: rgba(15, 23, 42, 0.85);
        }

        .step-number {
            font-size: 0.78rem;
            font-weight: 600;
            color: var(--accent);
            margin-bottom: 0.15rem;
            text-transform: uppercase;
            letter-spacing: 0.08em;
        }

        ul {
            margin: 0.35rem 0 0.55rem 1.1rem;
            padding: 0;
            color: var(--muted);
        }

        li {
            margin-bottom: 0.25rem;
        }

        .two-col {
            display: grid;
            grid-template-columns: minmax(0, 1.55fr) minmax(0, 1.55fr);
            gap: 1.25rem;
        }

        .badge {
            display: inline-block;
            font-size: 0.75rem;
            padding: 0.18rem 0.55rem;
            border-radius: 999px;
            border: 1px solid var(--accent-soft);
            background: rgba(15, 23, 42, 0.9);
            color: var(--muted);
            margin-bottom: 0.15rem;
        }

        .quote {
            border-left: 3px solid var(--accent);
            padding-left: 0.7rem;
            margin-top: 0.45rem;
            font-size: 0.94rem;
            color: var(--muted);
            font-style: italic;
        }

        .impact-figure {
            margin-top: 0.8rem;
        }

        .impact-figure img {
            border-radius: 1rem;
        }

        footer {
            max-width: var(--max-width);
            margin: 0 auto;
            padding: 0 1.4rem 2.4rem;
            font-size: 0.8rem;
            color: var(--muted);
            border-top: 1px solid var(--border);
        }

        footer p {
            margin-top: 1rem;
        }

        @media (max-width: 880px) {
            .hero {
                grid-template-columns: minmax(0, 1fr);
            }
        }

        @media (max-width: 720px) {
            .nav {
                flex-direction: column;
                align-items: flex-start;
            }
            main, footer {
                padding-inline: 1.1rem;
            }
        }

        html {
            scroll-behavior: smooth;
        }
    </style>
</head>
<body>
<header>
    <div class="nav">
        <div class="nav-title">Deepfake Technology</div>
        <nav class="nav-links">
            <a href="#intro">Intro</a>
            <a href="#visual">Real vs Fake</a>
            <a href="#how-it-works">How It Works</a>
            <a href="#applications">Examples</a>
            <a href="#ethics">Ethics</a>
            <a href="#impact">Impact</a>
            <a href="#summary">Takeaways</a>
        </nav>
    </div>
</header>

<main>
    <!-- HERO -->
    <section id="intro">
        <div class="hero">
            <div>
                <div class="hero-tag">
                    <span class="dot"></span>
                    Visual guide · Deepfake media
                </div>
                <h1>Deepfakes: How Fake Media Looks Real</h1>
                <p class="hero-subtitle">
                    This website explains, in simple pictures and clear words, how
                    deepfake technology works, where it is used, and why it matters
                    for society and ethics.
                </p>
                <div class="meta">
                    <p>
                        <strong>Project focus:</strong> Deepfake technology as an advanced
                        information technology.<br />
                        <strong>Goal:</strong> Help viewers understand the pipeline
                        <em>visually</em> and then evaluate it using ethical lenses.
                    </p>
                </div>
            </div>

            <aside class="hero-figure" aria-label="Visual comparison of real and AI-generated faces">
                <div class="pill">
                    <span class="pill-icon">AI</span>
                    Real vs AI-generated faces
                </div>
                <div class="hero-img-grid" style="margin-top:0.6rem;">
                    <figure>
                        <img
                            src="https://images.pexels.com/photos/3760853/pexels-photo-3760853.jpeg?auto=compress&cs=tinysrgb&w=600"
                            alt="Photo of a real person looking at a screen"
                        />
                        <figcaption>Real person – original recording.</figcaption>
                    </figure>
                    <figure>
                        <img
                            src="https://images.pexels.com/photos/8386440/pexels-photo-8386440.jpeg?auto=compress&cs=tinysrgb&w=600"
                            alt="Stylized AI generated face representing a deepfake"
                        />
                        <figcaption>AI-generated face – realistic but synthetic.</figcaption>
                    </figure>
                </div>
                <p style="font-size:0.8rem;color:var(--muted);margin-top:0.4rem;">
                    Deepfakes make it hard to see the difference between what really
                    happened and what a model created.
                </p>
            </aside>
        </div>
    </section>

    <!-- SIMPLE VISUAL EXPLANATION -->
    <section id="visual">
        <h2>First Question: What Is a Deepfake?</h2>
        <div class="card-grid">
            <article class="card">
                <h3>One Sentence</h3>
                <p>
                    A deepfake is a video, image, or audio clip where an AI model
                    changes someone’s face or voice so it looks and sounds real, even
                    though the event never happened.
                </p>
            </article>
            <article class="card">
                <h3>Picture in Your Head</h3>
                <p>
                    Imagine taking thousands of photos of a person and giving them to a
                    very smart “copy machine.” That machine learns every detail of
                    their face and voice, and then can put that person into any scene
                    you want.
                </p>
            </article>
            <article class="card">
                <h3>Why It Matters</h3>
                <p>
                    These fakes are not just funny filters. They can change elections,
                    damage reputations, and be used for fraud and harassment.
                </p>
            </article>
        </div>
    </section>

    <!-- HOW IT WORKS -->
    <section id="how-it-works">
        <h2>How Deepfakes Work – Step by Step (With Pictures)</h2>
        <p>
            Below is a simple three-step pipeline. For each step, we show a short
            visual idea and use clear language.
        </p>

        <div class="step-grid">
            <div class="step">
                <div class="step-number">Step 1 · Collect Data</div>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/1181675/pexels-photo-1181675.jpeg?auto=compress&cs=tinysrgb&w=600"
                        alt="Many photos of faces on a screen representing training data"
                    />
                    <figcaption>
                        Many pictures and videos of the target person’s face and voice.
                    </figcaption>
                </figure>
                <p>
                    The model needs a lot of examples of one person. It learns how the
                    face looks from different angles, with different lighting and
                    expressions, and how their voice sounds.
                </p>
            </div>

            <div class="step">
                <div class="step-number">Step 2 · Train the Model (GAN)</div>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/1647976/pexels-photo-1647976.jpeg?auto=compress&cs=tinysrgb&w=600"
                        alt="Abstract AI training visualization with graphs"
                    />
                    <figcaption>
                        Generator vs discriminator: one creates fakes, the other checks
                        them.
                    </figcaption>
                </figure>
                <p>
                    A Generative Adversarial Network (GAN) has two parts: one network
                    tries to create fake images; another network tries to detect if
                    they are fake. Over time, the creator gets very good at making
                    images that fool the detector.
                </p>
            </div>

            <div class="step">
                <div class="step-number">Step 3 · Produce the Deepfake</div>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/6898859/pexels-photo-6898859.jpeg?auto=compress&cs=tinysrgb&w=600"
                        alt="Video editing timeline representing deepfake output"
                    />
                    <figcaption>
                        The trained model overlays the fake face/voice on a real video.
                    </figcaption>
                </figure>
                <p>
                    After training, the model can swap faces in a new video, change
                    lip movements to match new audio, or clone a voice to say
                    something completely different.
                </p>
            </div>
        </div>
    </section>

    <!-- APPLICATIONS -->
    <section id="applications">
        <h2>Where Are Deepfakes Used? (Concrete Examples)</h2>

        <div class="card-grid">
            <article class="card">
                <h3>Example 1 – Politics</h3>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/21067/pexels-photo.jpg?auto=compress&cs=tinysrgb&w=600"
                        alt="Crowd at a political rally"
                    />
                    <figcaption>
                        Fake speeches or statements that never happened.
                    </figcaption>
                </figure>
                <ul>
                    <li>AI voice calls that sound like real candidates.</li>
                    <li>Videos that show politicians saying things they never said.</li>
                    <li>
                        Can confuse voters and weaken trust in elections and news.
                    </li>
                </ul>
            </article>

            <article class="card">
                <h3>Example 2 – Fraud & Scams</h3>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/5380642/pexels-photo-5380642.jpeg?auto=compress&cs=tinysrgb&w=600"
                        alt="Person on a video call representing business communication"
                    />
                    <figcaption>
                        Fake video or voice calls from “your boss” or “your bank.”
                    </figcaption>
                </figure>
                <ul>
                    <li>Scammers clone a CEO’s face or voice.</li>
                    <li>Employees are tricked into sending money or data.</li>
                    <li>
                        Old rule “If you see them on video, it’s safe” no longer works.
                    </li>
                </ul>
            </article>

            <article class="card">
                <h3>Example 3 – Non-consensual Content</h3>
                <figure>
                    <img
                        src="https://images.pexels.com/photos/5723267/pexels-photo-5723267.jpeg?auto=compress&cs=tinysrgb&w=600"
                        alt="Person looking upset at their phone"
                    />
                    <figcaption>
                        People’s faces placed into explicit or harmful videos.
                    </figcaption>
                </figure>
                <ul>
                    <li>
                        Often targets women and creates serious psychological harm.
                    </li>
                    <li>Hard to remove once shared online.</li>
                    <li>Raises strong questions about consent and dignity.</li>
                </ul>
            </article>
        </div>
    </section>

    <!-- ETHICS -->
    <section id="ethics">
        <h2>How We Judge Deepfakes: Two Ethical Lenses</h2>
        <div class="two-col">
            <article class="card">
                <span class="badge">Lens 1 · Utilitarianism</span>
                <h3>Focus: Total Harm vs Total Benefit</h3>
                <p>
                    We ask: “Does this technology create more overall good than harm
                    for society?”
                </p>
                <ul>
                    <li><strong>Possible good:</strong> film effects, education, accessibility.</li>
                    <li>
                        <strong>Large harms:</strong> disinformation, fraud, harassment,
                        and loss of trust in media.
                    </li>
                </ul>
                <p class="quote">
                    Our conclusion: right now, without strong safeguards, the harms of
                    deepfakes are bigger than the benefits.
                </p>
            </article>

            <article class="card">
                <span class="badge">Lens 2 · Deontology</span>
                <h3>Focus: Rights, Duties, and Respect</h3>
                <p>
                    We ask: “Does this respect people’s rights, no matter the outcome?”
                </p>
                <ul>
                    <li>Uses someone’s face or voice without consent.</li>
                    <li>Intentionally creates something that looks true but is false.</li>
                    <li>Can seriously damage a person’s reputation and privacy.</li>
                </ul>
                <p class="quote">
                    Under this lens, most harmful deepfakes are wrong even if they
                    brought some benefit, because they ignore consent and truth.
                </p>
            </article>
        </div>
    </section>

    <!-- IMPACT -->
    <section id="impact">
        <h2>Big Picture: What Deepfakes Do to Society</h2>
        <div class="card">
            <div class="two-col">
                <div>
                    <h3>Three Main Areas of Impact</h3>
                    <ul>
                        <li><strong>Trust:</strong> People stop believing photos and videos.</li>
                        <li>
                            <strong>Safety:</strong> Easier for attackers to scam, blackmail, and
                            mislead.
                        </li>
                        <li>
                            <strong>Democracy:</strong> Voters may not know what is real during
                            elections.
                        </li>
                    </ul>
                    <p>
                        When fake content becomes normal, even real evidence can be
                        called “fake.” This is sometimes called the
                        <em>liar’s dividend</em>.
                    </p>
                </div>
                <div class="impact-figure">
                    <figure>
                        <img
                            src="https://images.pexels.com/photos/6476584/pexels-photo-6476584.jpeg?auto=compress&cs=tinysrgb&w=600"
                            alt="Person fact-checking content on a laptop"
                        />
                        <figcaption>
                            Society needs stronger verification, not only better fakes.
                        </figcaption>
                    </figure>
                </div>
            </div>
        </div>
    </section>

    <!-- SUMMARY -->
    <section id="summary">
        <h2>Our Main Takeaways & Recommendations</h2>
        <div class="card-grid">
            <article class="card">
                <h3>Clear Takeaways</h3>
                <ul>
                    <li>Deepfakes blend technical innovation with serious social risk.</li>
                    <li>
                        The same tools that power creative media also fuel fraud and
                        disinformation.
                    </li>
                    <li>
                        Ordinary people, not just experts, are now targets of synthetic
                        media.
                    </li>
                </ul>
            </article>

            <article class="card">
                <h3>What Should Happen Next?</h3>
                <ul>
                    <li>Technical watermarks and media provenance systems.</li>
                    <li>Stronger laws around consent and harmful use of likeness.</li>
                    <li>Education so people know how to question what they see.</li>
                </ul>
            </article>

            <article class="card">
                <h3>Our Position</h3>
                <p>
                    Deepfake technology is not “good” or “bad” by itself, but in its
                    current real-world use the negative effects are dominant. Our
                    ethical evaluation suggests we must guide this technology with
                    strong governance if we want its creative benefits without
                    accepting large-scale harm.
                </p>
            </article>
        </div>
    </section>
</main>

<footer>
    <p>
        This site is part of a course project on information technology and
        ethics. It aims to explain deepfake technology visually and clearly for
        academic discussion.
    </p>
</footer>
</body>
</html>
